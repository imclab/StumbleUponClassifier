0.876809206097      benchmark
0.877067308592      tfidf, topics, alchemy_cats, logistic regression

20 Fold CV Score:  0.868589992055 100 topics @ 50 iterations
20 Fold CV Score:  0.869352875213 100 topics @ 1000 iterations
20 Fold CV Score:  0.866330729295 500 topics @ 1000 iterations
20 Fold CV Score:  0.868670652855 50 topics @ 1500 iterations
20 Fold CV Score:  0.870306119029 120 topics @ 2000 iterations training on full.corpus
20 Fold CV Score:  0.870045281254 120 topics @ 2000 iterations training on only train.corpus

/usr/bin/python2.7 /media/Storage/workspace/su-clf/grid_searcher.py
# Tuning hyper-parameters for roc_auc

Best parameters set found on development set:

SVC(C=1, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,
  kernel=linear, max_iter=-1, probability=True, random_state=None,
  shrinking=True, tol=0.001, verbose=False)

Grid scores on development set:

0.759 (+/-0.010) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}
0.714 (+/-0.054) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.0001}
0.800 (+/-0.007) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}
0.759 (+/-0.010) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.0001}
0.872 (+/-0.002) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}
0.800 (+/-0.007) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}
0.871 (+/-0.004) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}
0.872 (+/-0.002) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001}
0.876 (+/-0.003) for {'kernel': 'linear', 'C': 1}
0.867 (+/-0.005) for {'kernel': 'linear', 'C': 10}
0.857 (+/-0.006) for {'kernel': 'linear', 'C': 100}
0.837 (+/-0.009) for {'kernel': 'linear', 'C': 1000}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

        0.0       0.76      0.86      0.80      1771
        1.0       0.85      0.74      0.79      1927

avg / total       0.81      0.80      0.80      3698



Process finished with exit code 0
